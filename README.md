# Gradient Descent and Neural Network Implementation

## Problem Statement

**Gradient Descent:**

Implement gradient descent for a simple linear regression model on a small dataset of 12 samples. The goal is to minimize the loss function by iteratively updating the model's parameters.

**Neural Network:**

Build and train a neural network to classify handwritten characters from the eMNIST dataset. The network should achieve high accuracy on the test set.

## Original Question

**Gradient Descent:**

> Implement gradient descent for a small dataset of 12 samples.
> 
> The model makes predictions in the following way: `yp = ϕ₀ + ϕ₁ * x₁ + ϕ₂ * x₂² + ϕ₃ * x₃`
> 
> ...

**Neural Network:**

> Create the following neural networks and print the loss, accuracy for 5 epochs:
> 1. Neural network with 3 hidden layers, each hidden layer with ReLU activation. The hidden layers are of the sizes [100, 50, 50]
> 2. Neural network with 3 hidden layers, each hidden layer with sigmoid activation. The hidden layers are of the sizes [150, 75, 50]
> 3. Neural network with 3 hidden layers, each hidden layer with tanh activation. The hidden layers are of the sizes [150, 75, 50]
